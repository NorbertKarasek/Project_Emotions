{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:12.169035Z",
     "start_time": "2025-03-30T14:15:10.006709Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%pip install pyod\n",
    "import os\n",
    "import numpy as np\n",
    "from pyod.models import hbos\n",
    "from pyod.utils.data import evaluate_print\n",
    "from sklearn.metrics import confusion_matrix,cohen_kappa_score,f1_score\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:14.074490Z",
     "start_time": "2025-03-30T14:15:14.069012Z"
    }
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Trial or epoch = eeg segment\n",
    "#####\n",
    "\n",
    "channels = 32\n",
    "seconds = 0.5    # Size of each segment we want\n",
    "fs = 256.0         # Dtaset eeg sampling rate\n",
    "data_portion = 1\n",
    "save_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Data/TrainData/features_raw.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Fp1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:47.466023Z",
     "start_time": "2025-03-30T14:15:47.324016Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df['AF3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:49.812643Z",
     "start_time": "2025-03-30T14:15:49.638029Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df['F3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:19:27.401633Z",
     "start_time": "2025-03-30T14:19:27.348391Z"
    }
   },
   "outputs": [],
   "source": [
    "class EEGDataset2:\n",
    "    def __init__(self, train_csv, seconds=0.500, fs=256, data_portion=1, normalize=True, isolated_channels=False):\n",
    "        assert data_portion > 0.0 and data_portion <= 1, 'data_portion should be > 0 and <= 1'\n",
    "        \n",
    "        self.isolated_channels = isolated_channels\n",
    "        self.normalize = normalize\n",
    "        self.train_csv = train_csv\n",
    "        self.seconds = seconds\n",
    "        self.fs = fs\n",
    "        self.data_portion = data_portion\n",
    "    \n",
    "    def get_data(self):\n",
    "        df = pd.read_csv(self.train_csv)\n",
    "        array_size = int(self.seconds * self.fs)\n",
    "        # Dataset shape is: [data x channels]\n",
    "        # we want shape: [segments x features]\n",
    "        \n",
    "        if self.normalize:\n",
    "            df = (df - df.mean()) / df.std()\n",
    "        \n",
    "        if self.isolated_channels:\n",
    "            channels = []\n",
    "            for channel in df.columns[0:32]:\n",
    "                isolated_channel = []\n",
    "                for i in range(int(len(df) / array_size)):\n",
    "                    isolated_channel.append(df[channel][i*array_size:(i+1)*array_size].to_numpy())\n",
    "                channels.append(np.array(isolated_channel))\n",
    "            return np.array(channels)\n",
    "            \n",
    "        dataset = []\n",
    "        \n",
    "        for channel in df.columns[0:32]:\n",
    "            for i in range(int(len(df) / array_size)):\n",
    "                dataset.append(df[channel][i*array_size:(i+1)*array_size].to_numpy())\n",
    "                \n",
    "        return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:19:29.933659Z",
     "start_time": "2025-03-30T14:19:29.780613Z"
    }
   },
   "outputs": [],
   "source": [
    "train_csv = r'Data\\features_raw.csv'\n",
    "eegDataset = EEGDataset2(train_csv, seconds, fs, data_portion, normalize=True)\n",
    "\n",
    "train_dataset = eegDataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:19:32.999455Z",
     "start_time": "2025-03-30T14:19:32.981844Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:19:39.861531Z",
     "start_time": "2025-03-30T14:19:35.272740Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = hbos.HBOS(n_bins=17, alpha=0.07, tol=0.5,contamination=.15)\n",
    "clf.fit(train_dataset)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"TRAINING THE MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:02.173836Z",
     "start_time": "2025-03-30T14:20:00.034956Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(train_dataset)\n",
    "\n",
    "for i in range(len(pred)):    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "    \n",
    "    if pred[i] == 1: plt.plot(range(128*i,128*(i+1)), train_dataset[i], color='red')\n",
    "    else: plt.plot(range(128*i,128*(i+1)), train_dataset[i], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "#importing Libraries \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "tf.keras.backend.clear_session()\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn import datasets, tree, linear_model, svm\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('Data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is a dataset of EEG brainwave data that has been processed with original strategy of statistical extraction \n",
    "    the data set consist brain signal of one male and one feamle by showing them different scenes (like Emotional,Funny,Death,Nature scenes) \n",
    "    and took their brain signal in these particular environments'''\n",
    "\n",
    "#Reading dataset\n",
    "data = pd.read_csv(\"Data/TrainData/emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chceking length of dataset\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:23.443537Z",
     "start_time": "2025-03-30T14:20:23.399603Z"
    }
   },
   "outputs": [],
   "source": [
    "#Seprarting Positive,Neagtive and Neutral dataframes for plortting\n",
    "pos = data.loc[data[\"label\"]==\"POSITIVE\"]\n",
    "sample_pos = pos.loc[2, 'fft_0_b':'fft_749_b']\n",
    "neg = data.loc[data[\"label\"]==\"NEGATIVE\"]\n",
    "sample_neg = neg.loc[0, 'fft_0_b':'fft_749_b']\n",
    "neu = data.loc[data[\"label\"]==\"NEUTRAL\"]\n",
    "sample_neu = neu.loc[1, 'fft_0_b':'fft_749_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:25.054384Z",
     "start_time": "2025-03-30T14:20:24.904550Z"
    }
   },
   "outputs": [],
   "source": [
    "#plottintg Dataframe distribution\n",
    "plt.figure(figsize=(25,7))\n",
    "plt.title(\"Data distribution of Emotions\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.countplot(x='label', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:30.223404Z",
     "start_time": "2025-03-30T14:20:30.076943Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Positive DataFrame\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(range(len(sample_pos)), sample_pos)\n",
    "plt.title(\"Graph of Positive Columns\")\n",
    "plt.show()\n",
    "'''As we can noticed the most of the Negative Signals are from greater than 600 to and less than than -600'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:32.928682Z",
     "start_time": "2025-03-30T14:20:32.757170Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Negative DataFrame\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(range(len(sample_neg)), sample_neg)\n",
    "plt.title(\"Graph of Negative Columns\")\n",
    "plt.show()\n",
    "'''As we can noticed the most of the Negative Signals are from less than 600 to and greater than -600'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:39.257432Z",
     "start_time": "2025-03-30T14:20:39.086077Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Neutral DataFrame\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(range(len(sample_neu)), sample_neu)\n",
    "plt.title(\"Graph of Neutral Columns\")\n",
    "plt.show()\n",
    "'''As we can see the most of the Neutral Signals ae in between -50 to 250 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:41.154381Z",
     "start_time": "2025-03-30T14:20:41.148687Z"
    }
   },
   "outputs": [],
   "source": [
    "def Transform_data(data):\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "    #Encoding Lables into numbers\n",
    "    encoding_data = ({'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 2} )\n",
    "    data_encoded = data.replace(encoding_data)\n",
    "    #getting brain signals into x variable\n",
    "    x=data_encoded.drop([\"label\"]  ,axis=1)\n",
    "    #getting labels into y variable\n",
    "    y = data_encoded.loc[:,'label'].values\n",
    "    scaler = StandardScaler()\n",
    "    #scaling Brain Signals\n",
    "    scaler.fit(x)\n",
    "    X = scaler.transform(x)\n",
    "    #One hot encoding Labels \n",
    "    Y = to_categorical(y)\n",
    "    return X,Y, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:43.081740Z",
     "start_time": "2025-03-30T14:20:42.867901Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calling above function and splitting dataset into train and test\n",
    "X,Y, scaler = Transform_data(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:43.906390Z",
     "start_time": "2025-03-30T14:20:43.901365Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking shape of dataset\n",
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:49.366389Z",
     "start_time": "2025-03-30T14:20:49.360547Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = tf.keras.Input(shape=(x_train.shape[1],))\n",
    "    # Zmiana kształtu z (liczba_cech,) na (liczba_cech, 1)\n",
    "    reshaped = tf.keras.layers.Reshape((x_train.shape[1], 1))(inputs)\n",
    "\n",
    "    gru = tf.keras.layers.GRU(256, return_sequences=True)(reshaped)\n",
    "    flatten = tf.keras.layers.Flatten()(gru)\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(flatten)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:20:51.424623Z",
     "start_time": "2025-03-30T14:20:51.157774Z"
    }
   },
   "outputs": [],
   "source": [
    "#cretaing model\n",
    "lstmmodel = create_model()\n",
    "#Compiling model \n",
    "lstmmodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:57:46.840209Z",
     "start_time": "2025-03-30T14:20:55.539407Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training and Evaluting model\n",
    "history = lstmmodel.fit(x_train, y_train, epochs = 10, validation_split=0.1)\n",
    "loss, acc = lstmmodel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:21:27.408561Z",
     "start_time": "2025-03-30T15:21:27.340778Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loss and Accuracy of model on Testiong Dataset \n",
    "print(f\"Loss on testing: {loss*100}\",f\"\\nAccuracy on Training: {acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:21:43.304435Z",
     "start_time": "2025-03-30T15:21:29.612043Z"
    }
   },
   "outputs": [],
   "source": [
    "#predicting model on test set for plotting Confusion Matrix\n",
    "pred  = lstmmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:23:40.135047Z",
     "start_time": "2025-03-30T15:23:40.088795Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creation of Function of Confusion Matrix\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(data.label.unique()))\n",
    "    plt.xticks(tick_marks, names, rotation=90)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:23:42.418879Z",
     "start_time": "2025-03-30T15:23:42.411162Z"
    }
   },
   "outputs": [],
   "source": [
    "#after getting prediction checking maximum score prediction to claim which emotion this brain signal belongs to\n",
    "pred1 = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:23:43.423182Z",
     "start_time": "2025-03-30T15:23:43.414118Z"
    }
   },
   "outputs": [],
   "source": [
    "#inversing the one hot encoding\n",
    "y_test1 =   np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:23:44.761080Z",
     "start_time": "2025-03-30T15:23:44.752674Z"
    }
   },
   "outputs": [],
   "source": [
    "#printing first 10 Actual and predicted outputs of Test brain signals\n",
    "print(\"Predicted:  \",pred1[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Actual: \",y_test1[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:23:49.891871Z",
     "start_time": "2025-03-30T15:23:49.434881Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Confusion matrix of Lstm Model\n",
    "cm = confusion_matrix(y_test1, pred1)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.rcParams[\"figure.figsize\"]=(20,5)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,[\"Neutral\",\"Positive\",\"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:23:54.067902Z",
     "start_time": "2025-03-30T15:23:54.058317Z"
    }
   },
   "outputs": [],
   "source": [
    "names1 = [\"Neutral\",\"Positive\",\"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:24:18.289408Z",
     "start_time": "2025-03-30T15:23:55.791570Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training our dataset on different Classifiers to check the results and creating their classification reports\n",
    "#NAves Bayes Clssifier\n",
    "Classifier_gnb = GaussianNB().fit(x_train, np.argmax(y_train,axis=1))\n",
    "pred_gnb = Classifier_gnb.predict(x_test)\n",
    "print ('\\n*\\t\\tClassification Report GNB:\\n', classification_report(np.argmax(y_test,axis=1), pred_gnb))\n",
    "confusion_matrix_graph = confusion_matrix(np.argmax(y_test,axis=1), pred_gnb)\n",
    "### Support Vector Machine\n",
    "\n",
    "Classifier_svm = svm.SVC(kernel='linear').fit(x_train, np.argmax(y_train,axis=1))\n",
    "pred_svm = Classifier_svm.predict(x_test)\n",
    "print ('\\n*\\t\\tClassification Report SVM:\\n', classification_report(np.argmax(y_test,axis=1), pred_svm))\n",
    "confusion_matrix_graph = confusion_matrix(np.argmax(y_test,axis=1), pred_svm)\n",
    "### Logistic Regression\n",
    "\n",
    "Classifier_LR = linear_model.LogisticRegression(solver = 'liblinear', C = 75).fit(x_train, np.argmax(y_train,axis=1))\n",
    "pred_LR = Classifier_LR.predict(x_test)\n",
    "print ('\\n*\\t\\tClassification Report LR:\\n', classification_report(np.argmax(y_test,axis=1), pred_LR))\n",
    "confusion_matrix_graph = confusion_matrix(np.argmax(y_test,axis=1), pred_LR)\n",
    "### Decision Tree Regressor\n",
    "\n",
    "Classifier_dt = tree.DecisionTreeClassifier().fit(x_train, np.argmax(y_train,axis=1))\n",
    "pred_dt = Classifier_dt.predict(x_test)\n",
    "print ('\\n*\\t\\tClassification Report Deccsion Tree:\\n', classification_report(np.argmax(y_test,axis=1), pred_dt))\n",
    "confusion_matrix_graph = confusion_matrix(np.argmax(y_test,axis=1), pred_dt)\n",
    "### Random Forest\n",
    "\n",
    "Classifier_forest = RandomForestClassifier(n_estimators = 50, random_state = 0).fit(x_train,np.argmax(y_train,axis=1))\n",
    "pred_fr = Classifier_dt.predict(x_test)\n",
    "\n",
    "\n",
    "print ('\\n*\\t\\tClassification Report Random Forest:\\n', classification_report(np.argmax(y_test,axis=1), pred_fr))\n",
    "confusion_matrix_graph = confusion_matrix(np.argmax(y_test,axis=1), pred_fr)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "classifiers = [GaussianNB(),svm.SVC(kernel='linear'),\n",
    "               linear_model.LogisticRegression(solver = 'liblinear', C = 75),\n",
    "               RandomForestClassifier(n_estimators = 50, random_state = 0)]\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "for cls in classifiers:\n",
    "    cls.fit(x_train,np.argmax(y_train,axis=1))\n",
    "\n",
    "colors = [ 'YlOrBr', 'GnBu', 'Pastel2', 'PuRd']\n",
    "for cls, ax, c in zip(classifiers, axes.flatten(), colors):\n",
    "    y_pred = cls.predict(x_test)\n",
    "    cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=names1)\n",
    "    disp.plot(ax=ax, cmap=c)\n",
    "    ax.title.set_text(type(cls).__name__)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:24:38.096273Z",
     "start_time": "2025-03-30T15:24:24.591329Z"
    }
   },
   "outputs": [],
   "source": [
    "#Classification Report of Lstm model\n",
    "print('\\n*\\t\\tClassification Report OF Brain Waves LSTM:\\n', classification_report(np.argmax(y_test,axis=1), np.argmax(lstmmodel.predict(x_test),axis=1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T15:25:02.907283Z",
     "start_time": "2025-03-30T15:25:02.645687Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting Graph of Lstm model Training, Loss and Accuracy\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model Loss\",fontsize=20)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train loss', 'validation loss'], loc ='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\",fontsize=20)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['training accuracy', 'validation accuracy'], loc ='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis modelu w formacie HDF5\n",
    "lstmmodel.save('Model/model.keras')\n",
    "\n",
    "# Zapis skalera za pomocą pickle\n",
    "import pickle\n",
    "with open('Model/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = data.loc[data[\"label\"]==\"NEGATIVE\"]\n",
    "sample_neg = neg.loc[0, :'fft_749_b']\n",
    "print(sample_neg)\n",
    "\n",
    "# Konwersja series do DataFrame (jeden wiersz)\n",
    "sample_neg_df = sample_neg.to_frame().T\n",
    "\n",
    "# Zapis do pliku CSV\n",
    "sample_neg_df.to_csv('Data/Samples/new_sample_negative.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:21:14.570382Z",
     "start_time": "2025-03-30T16:21:14.538609Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = data.loc[data[\"label\"]==\"POSITIVE\"]\n",
    "pos_reset = pos.reset_index(drop=True)\n",
    "sample_pos = pos_reset.loc[0, :'fft_749_b']\n",
    "print(sample_pos)\n",
    "\n",
    "# Konwersja series do DataFrame (jeden wiersz)\n",
    "sample_pos_df = sample_pos.to_frame().T\n",
    "\n",
    "# Zapis do pliku CSV\n",
    "sample_pos_df.to_csv('Data/Samples/new_sample_positive.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:23:07.641323Z",
     "start_time": "2025-03-30T16:23:07.601721Z"
    }
   },
   "outputs": [],
   "source": [
    "neu = data.loc[data[\"label\"]==\"NEUTRAL\"]\n",
    "neu_reset = neu.reset_index(drop=True)\n",
    "sample_neu = neu_reset.loc[0, :'fft_749_b']\n",
    "print(sample_neu)\n",
    "\n",
    "# Konwersja series do DataFrame (jeden wiersz)\n",
    "sample_neu_df = sample_neu.to_frame().T\n",
    "\n",
    "# Zapis do pliku CSV\n",
    "sample_neu_df.to_csv('Data/Samples/new_sample_neutral.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:37:25.961242Z",
     "start_time": "2025-03-30T16:37:25.023144Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 93959,
     "sourceId": 218459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1186683,
     "sourceId": 1985143,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30213,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
